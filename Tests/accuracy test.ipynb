{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a10044",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Created by Mathew Varghese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877fe32",
   "metadata": {},
   "source": [
    "This is a jupyter notebook To test the accuracy of pre-trained resnet, mobilenet and googlenet oon elephant and bird datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21240f3",
   "metadata": {},
   "source": [
    "Create that the Data set using web scraping idt. https://github.com/deliton/idt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5b37cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "4069cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "elephant_list=[385,386]\n",
    "bird_list=[134,15,11,8,7,137]\n",
    "test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8392e822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\\\\Elephant-000d83175cb611ec97a7fc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\\\\Elephant-007676ef5cb411ec8937fc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\\\\Elephant-00c2a6625cb311ecbeaafc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\\\\Elephant-00f674945cb411eca94ffc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\\\\Elephant-018962295cb611ec9644fc44828dc385.jpg']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = \"C:/Users/stlp/Documents/GitHub/idt/elephant_detector/Elephant\"\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "c5ff2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_image(image,model):\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    inputs = Variable(image_tensor)\n",
    "    inputs = inputs.to('cpu')\n",
    "    output = model(inputs)\n",
    "    index = output.data.cpu().numpy()\n",
    "    index=(-index).argsort()\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "933601d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acc_fn(animal_list,pred):\n",
    "\n",
    "    count=0\n",
    "    for item in pred:\n",
    "        items=[item[0][0],item[0][1],item[0][2],item[0][3],item[0][4]]\n",
    "#         items=[item[0][0]]\n",
    "        if any(key in items for key in animal_list):\n",
    "            count=count+1\n",
    "    accuracy=count/len(pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2d805477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_pred_fn(onlyfiles,model):\n",
    "    pred=[]\n",
    "    for file_path in onlyfiles:\n",
    "        frame=cv2.imread(file_path)\n",
    "        frame = cv2.resize(frame, (225,225), interpolation = cv2.INTER_AREA)\n",
    "        color_coverted = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image=Image.fromarray(color_coverted)\n",
    "        result=predict_image(pil_image,model)\n",
    "        pred.append(result)\n",
    "        if len(pred)%50==0:\n",
    "            print(len(pred), end=', ')\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "5531693d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, "
     ]
    }
   ],
   "source": [
    "model = models.googlenet(pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "9a02a304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294157152451309"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_fn(elephant_list,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3f40d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8294157152451309"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.googlenet(pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(elephant_list,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "845c883a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7844190732034922"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(elephant_list,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "6631446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\stlp/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000, 1050, 1100, 1150, 1200, 1250, 1300, 1350, 1400, 1450, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7669576897246474"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(elephant_list,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "421cad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\\\\bird-000df6fe5cb811ec840cfc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\\\\bird-0058b9e55cb911ec89c8fc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\\\\bird-007cc3885cb811ec9dd2fc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\\\\bird-009749875cb911eca167fc44828dc385.jpg',\n",
       " 'C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\\\\bird-00ff188f5cb811ecb121fc44828dc385.jpg']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypath = \"C:/Users/stlp/Documents/GitHub/idt/elephant_detector/bird\"\n",
    "onlyfiles = [join(mypath, f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "e5650f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5660948536831484"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.googlenet(pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(bird_list,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "ef12c512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4873864783047427"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(bird_list,pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2b3a36cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\stlp/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.42684157416750756"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "pred=test_pred_fn(onlyfiles,model)\n",
    "accuracy=test_acc_fn(bird_list,pred)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
